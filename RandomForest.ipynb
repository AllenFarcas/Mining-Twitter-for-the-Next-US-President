{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>text</th>\n",
       "      <th>SentiStrength</th>\n",
       "      <th>Vader</th>\n",
       "      <th>Textblob</th>\n",
       "      <th>Vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1278320583718178816</td>\n",
       "      <td>Business Group Complains Trump H-1B Reform Boo...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1278310669885026305</td>\n",
       "      <td>\"Who's the absent candidate now?...'Sleepy Joe...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1278346691171586049</td>\n",
       "      <td>That moron trump vows to veto the Defense Bill...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1278368973948694528</td>\n",
       "      <td>@ClareTyne @mesainy @HKrassenstein @realDonald...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1278303504071905282</td>\n",
       "      <td>1. Funny how Biden barely criticizes Putin, an...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Tweet ID                                               text  \\\n",
       "0  1278320583718178816  Business Group Complains Trump H-1B Reform Boo...   \n",
       "1  1278310669885026305  \"Who's the absent candidate now?...'Sleepy Joe...   \n",
       "2  1278346691171586049  That moron trump vows to veto the Defense Bill...   \n",
       "3  1278368973948694528  @ClareTyne @mesainy @HKrassenstein @realDonald...   \n",
       "4  1278303504071905282  1. Funny how Biden barely criticizes Putin, an...   \n",
       "\n",
       "  SentiStrength     Vader  Textblob      Vote  \n",
       "0      Negative  Negative  Negative  Negative  \n",
       "1       Neutral  Negative  Positive   Neutral  \n",
       "2       Neutral  Negative  Negative  Negative  \n",
       "3      Negative  Positive   Neutral   Neutral  \n",
       "4       Neutral  Negative  Positive   Neutral  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import twitter_samples\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "def get_tweets_for_model(cleaned_tokens_list):\n",
    "    for tweet_tokens_index in range(0,len(cleaned_tokens_list)):\n",
    "        return dict([token, True] for token in cleaned_tokens_list[tweet_tokens_index]) \n",
    "    \n",
    "    \n",
    "def get_all_words(cleaned_tokens_list):\n",
    "    for tokens in cleaned_tokens_list:\n",
    "        for token in tokens:\n",
    "            yield token\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "data_ref=pd.read_excel('tweets.xlsx') \n",
    "\n",
    "string_vec=string.punctuation+\"--\"+'...'\n",
    "\n",
    "def remove_noise(tokens):\n",
    "    \n",
    "    \n",
    "    cleaned_tokens = []\n",
    "    for token, tag in pos_tag(tokens):\n",
    "        token = re.sub(\"(@[A-Za-z0-9_]+)\",\"\", token)\n",
    "\n",
    "        if tag.startswith('NN'):\n",
    "            pos = 'n'\n",
    "        elif tag.startswith('VB'):\n",
    "            pos = 'v'\n",
    "        else:\n",
    "            pos = 'a'\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        token = lemmatizer.lemmatize(token, pos)\n",
    "        \n",
    "        if len(token) > 0 and (token not in string_vec) and (token.lower() not in stop_words):\n",
    "                cleaned_tokens.append(token)\n",
    "    return cleaned_tokens\n",
    "\n",
    "\n",
    "\n",
    "import csv\n",
    "\n",
    "\n",
    "def deEmojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'',text)\n",
    "\n",
    "def preprocess_text2(text):\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','', text)\n",
    "    text = re.sub('@[^\\s]+','', text)\n",
    "    #text = text.lower().replace(\"ё\", \"е\")\n",
    "    text = text.replace(\"ё\", \"е\")\n",
    "    dat_str=data_ref.iloc[0]['full_text']\n",
    "    text = re.sub(dat_str[-10:-7],'\\'', text)\n",
    "    #text = re.sub('[^a-zA-Zа-яА-Я1-9]+',' ', text)\n",
    "    \n",
    "    text = re.sub(' +',' ', text)\n",
    "    text = re.sub(r' &amp','\\'', text)\n",
    "    text = re.sub(r'\\r','', text)\n",
    "    text = re.sub(r'\\n','', text)\n",
    "    text = re.sub('[$|@|#|%|^|&|*|\\(|\\)|\\\\|\\\"|\\\"]',' ', text)\n",
    "    text=deEmojify(text)\n",
    "    #print(text)\n",
    "    #text = re.sub('[^a-zA-Zа-яА-Я1-9]+',' ', text)\n",
    "    #text = re.sub(' +',' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "\n",
    "data=pd.read_csv('vote_all (1).csv',encoding = \"ISO-8859–1\")\n",
    "\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>text</th>\n",
       "      <th>SentiStrength</th>\n",
       "      <th>Vader</th>\n",
       "      <th>Textblob</th>\n",
       "      <th>Vote</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1278320583718178816</td>\n",
       "      <td>Business Group Complains Trump H-1B Reform Boosting U.S. Graduates. Big tech is whining that they will have to hire American instead of cheap fore...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Business Group Complains Trump H-1B Reform Boosting U.S. Graduates. Big tech is whining that they will have to hire American instead of cheap fore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1278310669885026305</td>\n",
       "      <td>\"Who's the absent candidate now?...'Sleepy Joe' is signaling that he's very much awake -- and dialed into a moment where Trump's leadership is rip...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Who's the absent candidate now?...'Sleepy Joe' is signaling that he's very much awake -- and dialed into a moment where Trump's leadership is ripe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1278346691171586049</td>\n",
       "      <td>That moron trump vows to veto the Defense Bill if it includes renaming bases. So once again, military salaries and defense preparedness are second...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>That moron trump vows to veto the Defense Bill if it includes renaming bases. So once again, military salaries and defense preparedness are second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1278368973948694528</td>\n",
       "      <td>@ClareTyne @mesainy @HKrassenstein @realDonaldTrump @NYCMayor @JoeBiden Yep.  Torturing that guy because the Dems donât care.</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Yep. Torturing that guy because the Dems donât care.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1278303504071905282</td>\n",
       "      <td>1. Funny how Biden barely criticizes Putin, and on the China virus doesnât criticize Xi.Â  Instead, he smears Trump.Â  The reason is the Democra...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1. Funny how Biden barely criticizes Putin, and on the China virus doesnât criticize Xi.Â  Instead, he smears Trump.Â  The reason is the Democra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Tweet ID  \\\n",
       "0  1278320583718178816   \n",
       "1  1278310669885026305   \n",
       "2  1278346691171586049   \n",
       "3  1278368973948694528   \n",
       "4  1278303504071905282   \n",
       "\n",
       "                                                                                                                                                    text  \\\n",
       "0  Business Group Complains Trump H-1B Reform Boosting U.S. Graduates. Big tech is whining that they will have to hire American instead of cheap fore...   \n",
       "1  \"Who's the absent candidate now?...'Sleepy Joe' is signaling that he's very much awake -- and dialed into a moment where Trump's leadership is rip...   \n",
       "2  That moron trump vows to veto the Defense Bill if it includes renaming bases. So once again, military salaries and defense preparedness are second...   \n",
       "3                        @ClareTyne @mesainy @HKrassenstein @realDonaldTrump @NYCMayor @JoeBiden Yep.  Torturing that guy because the Dems donât care.   \n",
       "4  1. Funny how Biden barely criticizes Putin, and on the China virus doesnât criticize Xi.Â  Instead, he smears Trump.Â  The reason is the Democra...   \n",
       "\n",
       "  SentiStrength     Vader  Textblob      Vote  \\\n",
       "0      Negative  Negative  Negative  Negative   \n",
       "1       Neutral  Negative  Positive   Neutral   \n",
       "2       Neutral  Negative  Negative  Negative   \n",
       "3      Negative  Positive   Neutral   Neutral   \n",
       "4       Neutral  Negative  Positive   Neutral   \n",
       "\n",
       "                                                                                                                                          processed_text  \n",
       "0  Business Group Complains Trump H-1B Reform Boosting U.S. Graduates. Big tech is whining that they will have to hire American instead of cheap fore...  \n",
       "1  Who's the absent candidate now?...'Sleepy Joe' is signaling that he's very much awake -- and dialed into a moment where Trump's leadership is ripe...  \n",
       "2  That moron trump vows to veto the Defense Bill if it includes renaming bases. So once again, military salaries and defense preparedness are second...  \n",
       "3                                                                                                 Yep. Torturing that guy because the Dems donât care.  \n",
       "4  1. Funny how Biden barely criticizes Putin, and on the China virus doesnât criticize Xi.Â  Instead, he smears Trump.Â  The reason is the Democra...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def preprocess_text2(text):\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','', str(text))\n",
    "    text = re.sub('@[^\\s]+','', text)\n",
    "    #text = text.lower().replace(\"ё\", \"е\")\n",
    "    text = text.replace(\"ё\", \"е\")\n",
    "    dat_str=data_ref.iloc[0]['full_text']\n",
    "    text = re.sub(dat_str[-10:-7],'\\'', text)\n",
    "    #text = re.sub('[^a-zA-Zа-яА-Я1-9]+',' ', text)\n",
    "    \n",
    "    text = re.sub(' +',' ', text)\n",
    "    text = re.sub(r' &amp','\\'', text)\n",
    "    text = re.sub(r'\\r','', text)\n",
    "    text = re.sub(r'\\n','', text)\n",
    "    text = re.sub('[$|@|#|%|^|&|*|\\(|\\)|\\\\|\\\"|\\\"]',' ', text)\n",
    "    text=deEmojify(text)\n",
    "    #print(text)\n",
    "    #text = re.sub('[^a-zA-Zа-яА-Я1-9]+',' ', text)\n",
    "    #text = re.sub(' +',' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "data[\"processed_text\"] =  data['text'].apply(preprocess_text2)\n",
    "pd.options.display.max_colwidth = 150\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words='english',ngram_range = (1,1),tokenizer = nltk.word_tokenize)\n",
    "#cv=CountVectorizer(stop_words='english')\n",
    "text_counts = cv.fit_transform(data['processed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text_counts,data['Vote'], test_size=0.25, random_state=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2097669, 871563)\n"
     ]
    }
   ],
   "source": [
    "#num_features=len(X_train.columns)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def replace_with_array(text):\n",
    "    if text=='\\tNegative'or text=='Negative':\n",
    "        array=1\n",
    "    elif text=='\\tPositive'or text=='Positive':\n",
    "        array=0\n",
    "    else:\n",
    "        array=2\n",
    "    return array\n",
    "Y_train.head()            \n",
    "Y_train[\"Vote_num\"] =  Y_train.apply(replace_with_array)\n",
    "Y_test[\"Vote_num\"] =  Y_test.apply(replace_with_array)\n",
    "\n",
    "\n",
    "#print(X_test[20].shape)\n",
    "#print(X_train.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622754     Neutral\n",
       "1864131    Neutral\n",
       "2642573    Neutral\n",
       "2086943    Neutral\n",
       "2315382    Neutral\n",
       "Name: Vote, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.head()         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "\n",
    "#tSVD = TruncatedSVD(n_components=1000)\n",
    "\n",
    "#Y_train=Y_train[\"Vote_num\"]\n",
    "#Y_test=Y_test[\"Vote_num\"]\n",
    "\n",
    "X_tr=X_train[0:100000,:]\n",
    "Y_tr=Y_train[0:100000]\n",
    "\n",
    "#scaler=MinMaxScaler()\n",
    "\n",
    "#X_trNew=scaler.fit_transform(X_tr)\n",
    "\n",
    "\n",
    "#X_tr_tSVD=tSVD.fit_transform(X_tr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier(n_estimators=1000,criterion='gini',warm_start=True)\n",
    "#for index in range(10):\n",
    "clf.fit(X_tr,Y_tr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(699223, 871563)\n",
      "(699223,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_tsNew=scaler.transform(X_test)\n",
    "\n",
    "print('Accuracy is ',clf.score(X_test,Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(Y_test, clf.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[116909,  69924,   5253],\n",
       "       [ 18374, 310771,  12528],\n",
       "       [  6887,  69530,  89047]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(Y_test, clf.predict(X_test),labels=['Negative','Neutral','Positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8177)\t1\n",
      "  (0, 11932)\t3\n",
      "  (0, 194726)\t1\n",
      "  (0, 205133)\t1\n",
      "  (0, 239119)\t1\n",
      "  (0, 259682)\t1\n",
      "  (0, 367006)\t1\n",
      "  (0, 394698)\t1\n",
      "  (0, 423396)\t1\n",
      "  (0, 579016)\t2\n",
      "  (0, 593743)\t1\n",
      "  (0, 641373)\t1\n",
      "  (0, 644949)\t1\n",
      "  (0, 659349)\t1\n",
      "  (1, 8177)\t2\n",
      "  (1, 11932)\t2\n",
      "  (1, 255139)\t1\n",
      "  (1, 292709)\t1\n",
      "  (1, 314191)\t1\n",
      "  (1, 336768)\t2\n",
      "  (1, 442342)\t1\n",
      "  (1, 444685)\t1\n",
      "  (1, 526976)\t1\n",
      "  (1, 533085)\t1\n",
      "  (1, 613192)\t1\n",
      "  :\t:\n",
      "  (699219, 742367)\t1\n",
      "  (699219, 742615)\t2\n",
      "  (699219, 780517)\t1\n",
      "  (699219, 793096)\t1\n",
      "  (699220, 207945)\t1\n",
      "  (699220, 460291)\t1\n",
      "  (699220, 492394)\t1\n",
      "  (699220, 506702)\t1\n",
      "  (699221, 11932)\t1\n",
      "  (699221, 64904)\t1\n",
      "  (699221, 106192)\t1\n",
      "  (699221, 109607)\t1\n",
      "  (699221, 201880)\t1\n",
      "  (699221, 216342)\t1\n",
      "  (699221, 366458)\t1\n",
      "  (699221, 409352)\t1\n",
      "  (699221, 490796)\t1\n",
      "  (699221, 576677)\t1\n",
      "  (699221, 591034)\t1\n",
      "  (699221, 691705)\t1\n",
      "  (699221, 744565)\t1\n",
      "  (699222, 0)\t3\n",
      "  (699222, 11932)\t1\n",
      "  (699222, 124247)\t1\n",
      "  (699222, 580729)\t1\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.728899077976554\n"
     ]
    }
   ],
   "source": [
    "clf=RandomForestClassifier(n_estimators=80,criterion='entropy').fit(X_tr,Y_tr)\n",
    "\n",
    "\n",
    "print('Accuracy is ',clf.score(X_test,Y_test))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "X_ts=X_test[0:100000,:]\n",
    "Y_ts=Y_test[0:100000]\n",
    "print('done')\n",
    "parameters = {'criterion':('gini', 'entropy'), 'n_estimators':[60,80,100,120]}\n",
    "RFC = RandomForestClassifier()\n",
    "clf_Grid=GridSearchCV(RFC, parameters).fit(X_tr,Y_tr)\n",
    "print('Best params for Random forest are ',clf_Grid.best_params_)\n",
    "\n",
    "RFC.set_params(criterion=clf_Grid.best_params_['criterion'], n_estimators= clf_Grid.best_params_['n_estimators'])\n",
    "RFC.fit(X_tr,y_tr)\n",
    "\n",
    "print('Accuracy is ',RFC.score(X_ts,Y_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true, RFC.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words='english',ngram_range = (1,1),tokenizer = nltk.word_tokenize)\n",
    "#cv=CountVectorizer(stop_words='english')\n",
    "text_counts = cv.fit_transform(data[0:700000]['processed_text'])\n",
    "\n",
    "X_train, X_testNew, Y_train, Y_testNew = train_test_split(text_counts,data[0:700000]['Vote']\\\n",
    "                                                          , test_size=0.25, random_state=5)\n",
    "\n",
    "def replace_with_array(text):\n",
    "    if text=='\\tNegative'or text=='Negative':\n",
    "        array=1\n",
    "    elif text=='\\tPositive'or text=='Positive':\n",
    "        array=0\n",
    "    else:\n",
    "        array=2\n",
    "    return array\n",
    "Y_train.head()            \n",
    "Y_train[\"Vote_num\"] =  Y_train.apply(replace_with_array)\n",
    "Y_testNew[\"Vote_num\"] =  Y_testNew.apply(replace_with_array)\n",
    "\n",
    "X_tr=X_train[0:100000,:]\n",
    "Y_tr=Y_train[0:100000]\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=100,criterion='gini').fit(X_tr,Y_tr)\n",
    "\n",
    "print('Accuracy is ',clf.score(X_testNew,Y_testNew))\n",
    "print(classification_report(y_true, clf.predict(X_testNew)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(n_estimators=15,criterion='entropy').fit(X_train,Y_train)\n",
    "print('Accuracy is ',clf.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import xgb\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "tSVD = TruncatedSVD(n_components=10000)\n",
    "X_tr_tSVD=tSVD.fit_transform(X_train)\n",
    "X_ts_tSVD=tSVD.transform(X_test)\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=10).fit(X_tr_tSVD,Y_train)\n",
    "print('Accuracy is ',clf.score(X_ts_tSVD,Y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('lala')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "error=0\n",
    "for index in range(int(X_test.shape[0])):\n",
    "    x=X_test[index]\n",
    "    x=x.todense()\n",
    "    y=Y_ts_tensor[index]\n",
    "    #x=torch.from_numpy(x)\n",
    "    x=torch.Tensor(x)\n",
    "    y_predict=net_model.net(x)\n",
    "    error=error+(y_predict!=y)\n",
    "\n",
    "print(error)\n",
    "\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(Y_train.iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "class Net(torch.nn.Module):\n",
    "        def __init__(self, n_feature, n_hidden=100,n_hidden12=100, n_output=3):\n",
    "                super(Net, self).__init__()\n",
    "                self.hidden1 = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n",
    "                \n",
    "                self.hidden12=torch.nn.Linear(n_hidden,n_hidden12)\n",
    "                self.predict = torch.nn.Linear(n_hidden12, n_output)   # output layer\n",
    "\n",
    "        def net(self, x):\n",
    "                x = F.relu(self.hidden1(x))      # activation function for hidden layer\n",
    "                \n",
    "                x=torch.tanh(self.hidden12(x))\n",
    "                x=self.predict(x)\n",
    "                x=F.softmax(x,dim=1)          # linear output\n",
    "                return x\n",
    "            \n",
    "class LSTM(nn.Module):\n",
    "        def __init__(self, input_shape=458750, n_actions=3):\n",
    "                super(LSTM, self).__init__()\n",
    "                self.lstm = nn.LSTM(input_shape, 100)\n",
    "                self.hidden2tag = nn.Linear(100, n_actions)\n",
    "\n",
    "        def net(self, x):\n",
    "                out1,_ = self.lstm(x)\n",
    "                out1 = F.tanh(self.hidden2tag(out1))\n",
    "                out1=torch.max(F.softmax(out1))\n",
    "\n",
    "                return out1\n",
    "            \n",
    "net_model=Net(n_feature=int(X_train.shape[1]))\n",
    "optimizer = torch.optim.Adam(net_model.parameters(), lr=0.01)\n",
    "print('start')\n",
    "Y_tr_tensor = (Y_train[\"Sentiment_array\"].values)\n",
    "Y_ts_tensor = (Y_test[\"Sentiment_array\"].values)\n",
    "\n",
    "for index in range(int(X_train.shape[0])): \n",
    "    optimizer.zero_grad()\n",
    "    print(index)\n",
    "    x=X_train[index]\n",
    "    \n",
    "    y=torch.tensor(Y_tr_tensor[index])\n",
    "    loss_func = torch.nn.CrossEntropyLoss()\n",
    "    net_model.zero_grad()\n",
    "    \n",
    "    x=x.todense()\n",
    "    \n",
    "    x=torch.Tensor(x)\n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    net_out=net_model.net(x)\n",
    "    \n",
    "    y=y.unsqueeze(0)\n",
    "    \n",
    "    loss = loss_func(net_out,y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)\n",
    "\n",
    "count=0\n",
    "with open('dataset_filt.jsonl','r') as f:\n",
    "        all_tokens_list=[]\n",
    "        for line in f:\n",
    "            count=count+1\n",
    "            tweet = json.loads(line)\n",
    "            text0=tweet[\"full_text\"]\n",
    "            text1= preprocess_text2(tweet[\"full_text\"]).lower()\n",
    "            \n",
    "            tokenized_text=word_tokenize(text1)\n",
    "            \n",
    "            all_tokens_list=all_tokens_list+(remove_noise(tokenized_text))\n",
    "            print(count)\n",
    "            \n",
    "            \n",
    "cv = CountVectorizer(stop_words='english',ngram_range = (1,1),tokenizer = nltk.word_tokenize)\n",
    "#cv=CountVectorizer(stop_words='english')\n",
    "text_counts = cv.fit_transform(data['processed_text'])\n",
    "\n",
    "#print(all_tokens_list)\n",
    "counts = Counter(all_tokens_list)\n",
    "#print(counts)\n",
    "#print(counts,'\\n')\n",
    "vocab = sorted(counts,  key=counts.get,reverse=True)\n",
    "#print(vocab,'\\n')\n",
    "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n",
    "#print(vocab_to_int)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(remove_noise(tokenized_text))\n",
    "\n",
    "\n",
    "print(all_tokens_list[3])\n",
    "all_pos_words = get_tweets_for_model(all_tokens_list)\n",
    "\n",
    "print(all_pos_words)\n",
    "\n",
    "print(remove_noise(tokenized_text))\n",
    "\n",
    "counts=Counter(remove_noise(tokenized_text))\n",
    "print(counts)\n",
    "max_fatures = 2000\n",
    "\n",
    "X = tokenizer.texts_to_sequences(['How','are','you'])\n",
    "vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "#print(vocab)\n",
    "print(X)\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
