{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "XK5y7TPvyjv9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Data preprocessing to removes @usernames,urls,symbols and makes all text lowercase\n",
    "def preprocess_text(text):\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL', text)\n",
    "    text = re.sub('@[^\\s]+','', text)\n",
    "    text = text.lower().replace(\"ё\", \"е\")\n",
    "    text = re.sub('[^a-zA-Zа-яА-Я]+',' ', text)\n",
    "    text = re.sub(' +',' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "#from google.colab import files   \n",
    "#uploaded = files.upload()\n",
    "#nltk.download('punkt')\n",
    "\n",
    "#Global variable\n",
    "batchsize = 100000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seNKaxWvyjv9"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "Misyylaiyjv9",
    "outputId": "c125b42d-656c-46b9-de16-9a6d00850f67"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>text</th>\n",
       "      <th>SentiStrength</th>\n",
       "      <th>Vader</th>\n",
       "      <th>Textblob</th>\n",
       "      <th>Vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1278320583718178816</td>\n",
       "      <td>Business Group Complains Trump H-1B Reform Boo...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1278346691171586049</td>\n",
       "      <td>That moron trump vows to veto the Defense Bill...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1278368975689220097</td>\n",
       "      <td>@JoeBiden Debate President Trump. PROVE you do...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1278368976960184320</td>\n",
       "      <td>@PamelaStovall6 @ChuckGrassley @realDonaldTrum...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1278368971314597890</td>\n",
       "      <td>@Jorgensen4POTUS @RealSpikeCohen Just found ou...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Tweet ID                                               text  \\\n",
       "0  1278320583718178816  Business Group Complains Trump H-1B Reform Boo...   \n",
       "1  1278346691171586049  That moron trump vows to veto the Defense Bill...   \n",
       "2  1278368975689220097  @JoeBiden Debate President Trump. PROVE you do...   \n",
       "3  1278368976960184320  @PamelaStovall6 @ChuckGrassley @realDonaldTrum...   \n",
       "4  1278368971314597890  @Jorgensen4POTUS @RealSpikeCohen Just found ou...   \n",
       "\n",
       "  SentiStrength     Vader  Textblob      Vote  \n",
       "0      Negative  Negative  Negative  Negative  \n",
       "1       Neutral  Negative  Negative  Negative  \n",
       "2       Neutral   Neutral   Neutral   Neutral  \n",
       "3       Neutral  Positive   Neutral   Neutral  \n",
       "4      Positive  Positive  Positive  Positive  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data from csv/excel/json\n",
    "#data=pd.read_csv('textblob_sample_5k.csv',encoding = 'unicode_escape')\n",
    "#data=pd.read_csv('textblob_sentiment_1M.csv',encoding = \"ISO-8859–1\")\n",
    "data = pd.read_csv('vote_all_no_conflict.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Gt3L49O_yjv-"
   },
   "outputs": [],
   "source": [
    "#data[\"processed_text\"] =  data['full_text'].apply(preprocess_text)\n",
    "data[\"processed_text\"] = data['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "CuOu1WcWyjv-",
    "outputId": "fcef20ab-2646-4848-ae94-125872dd440e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>text</th>\n",
       "      <th>SentiStrength</th>\n",
       "      <th>Vader</th>\n",
       "      <th>Textblob</th>\n",
       "      <th>Vote</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1278320583718178816</td>\n",
       "      <td>Business Group Complains Trump H-1B Reform Boosting U.S. Graduates. Big tech is whining that they will have to hire American instead of cheap fore...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>business group complains trump h b reform boosting u s graduates big tech is whining that they will have to hire american instead of cheap foreign...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1278346691171586049</td>\n",
       "      <td>That moron trump vows to veto the Defense Bill if it includes renaming bases. So once again, military salaries and defense preparedness are second...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>that moron trump vows to veto the defense bill if it includes renaming bases so once again military salaries and defense preparedness are second i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1278368975689220097</td>\n",
       "      <td>@JoeBiden Debate President Trump. PROVE you don’t have dementia. #DementiaJoeCantDebate #JoeBidenScaredToDebate</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>debate president trump prove you don t have dementia dementiajoecantdebate joebidenscaredtodebate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1278368976960184320</td>\n",
       "      <td>@PamelaStovall6 @ChuckGrassley @realDonaldTrump Democrats are always saving @GOP dinosaurs like grassley after they fvck up</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>democrats are always saving dinosaurs like grassley after they fvck up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1278368971314597890</td>\n",
       "      <td>@Jorgensen4POTUS @RealSpikeCohen Just found out about you and so far I love your policies and what you have to say. Ofc I still need to read more ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>just found out about you and so far i love your policies and what you have to say ofc i still need to read more about your stances and plans but i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Tweet ID  \\\n",
       "0  1278320583718178816   \n",
       "1  1278346691171586049   \n",
       "2  1278368975689220097   \n",
       "3  1278368976960184320   \n",
       "4  1278368971314597890   \n",
       "\n",
       "                                                                                                                                                    text  \\\n",
       "0  Business Group Complains Trump H-1B Reform Boosting U.S. Graduates. Big tech is whining that they will have to hire American instead of cheap fore...   \n",
       "1  That moron trump vows to veto the Defense Bill if it includes renaming bases. So once again, military salaries and defense preparedness are second...   \n",
       "2                                        @JoeBiden Debate President Trump. PROVE you don’t have dementia. #DementiaJoeCantDebate #JoeBidenScaredToDebate   \n",
       "3                            @PamelaStovall6 @ChuckGrassley @realDonaldTrump Democrats are always saving @GOP dinosaurs like grassley after they fvck up   \n",
       "4  @Jorgensen4POTUS @RealSpikeCohen Just found out about you and so far I love your policies and what you have to say. Ofc I still need to read more ...   \n",
       "\n",
       "  SentiStrength     Vader  Textblob      Vote  \\\n",
       "0      Negative  Negative  Negative  Negative   \n",
       "1       Neutral  Negative  Negative  Negative   \n",
       "2       Neutral   Neutral   Neutral   Neutral   \n",
       "3       Neutral  Positive   Neutral   Neutral   \n",
       "4      Positive  Positive  Positive  Positive   \n",
       "\n",
       "                                                                                                                                          processed_text  \n",
       "0  business group complains trump h b reform boosting u s graduates big tech is whining that they will have to hire american instead of cheap foreign...  \n",
       "1  that moron trump vows to veto the defense bill if it includes renaming bases so once again military salaries and defense preparedness are second i...  \n",
       "2                                                      debate president trump prove you don t have dementia dementiajoecantdebate joebidenscaredtodebate  \n",
       "3                                                                                 democrats are always saving dinosaurs like grassley after they fvck up  \n",
       "4  just found out about you and so far i love your policies and what you have to say ofc i still need to read more about your stances and plans but i...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 150\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "mrFXgX7gyjv-"
   },
   "outputs": [],
   "source": [
    "#Converting the text into tokens and getting the counts of each token based on the ngrams specified. \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "#cv = CountVectorizer(stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "cv = CountVectorizer(stop_words='english',ngram_range = (1,1),tokenizer = nltk.word_tokenize)\n",
    "#cv=CountVectorizer(stop_words='english')\n",
    "text_counts = cv.fit_transform(data['processed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9NfG8xM4yjv-",
    "outputId": "aac71285-aa41-4d9d-cb02-d357d42bdba4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2475775x247849 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 25453762 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_counts\n",
    "#cv.vocabulary_\n",
    "# Import LabelEncoder\n",
    "#from sklearn import preprocessing\n",
    "#creating labelEncoder\n",
    "#le = preprocessing.LabelEncoder()\n",
    "#label = le.fit_transform(data['Sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5793hDkByjv-"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "CSxG-j4syjv-"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text_counts,data['Vote'], test_size=0.25, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "FtQ0pvfaUKwV"
   },
   "outputs": [],
   "source": [
    "def batch_xy(input, output, batchsize):\n",
    "  for i in range(0, input.shape[0], batchsize):\n",
    "    yield input[i:i + batchsize, :], output[i:i + batchsize]\n",
    "\n",
    "def batch_x(input, batchsize):\n",
    "  for i in range(0, input.shape[0], batchsize):\n",
    "    yield input[i:i + batchsize, :]\n",
    "\n",
    "def report(name, target, pred):\n",
    "  label = \"[\" + name + \"] classification report:\"\n",
    "  print(label)\n",
    "  print(classification_report(target, pred)) \n",
    "\n",
    "def roc(name, model, input, target):\n",
    "  label = \"[\" + name + \"] roc curve:\"\n",
    "  print(label)\n",
    "  plt.figure()\n",
    "  roc_plt = plot_roc_curve(model, input, target)\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M19VQtQLyjv_",
    "outputId": "749a2187-fbf7-4a01-b353-8bdf6f3d06c2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score_RandomForest = 81.97%\n",
      "[Initial RF with text counts from Count Vectorizer] classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.88      0.76      0.81    192007\n",
      "     Neutral       0.76      0.95      0.85    261925\n",
      "    Positive       0.88      0.69      0.78    165012\n",
      "\n",
      "    accuracy                           0.82    618944\n",
      "   macro avg       0.84      0.80      0.81    618944\n",
      "weighted avg       0.83      0.82      0.82    618944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=100,criterion='gini',warm_start=True)\n",
    "#for index in range(10):\n",
    "\n",
    "for x, y in batch_xy(X_train, Y_train, batchsize):\n",
    "  clf.fit(x, y)\n",
    "  \n",
    "y_pred = np.array([])\n",
    "for x in batch_x(X_test, batchsize):\n",
    "  y_pred = np.append(y_pred, clf.predict(x))\n",
    "\n",
    "accuracy_score_clf = metrics.accuracy_score(y_pred, Y_test)\n",
    "print('accuracy_score_RandomForest = '+str('{:4.2f}'.format(accuracy_score_clf*100))+'%')\n",
    "report(\"Initial RF with text counts from Count Vectorizer\", Y_test, y_pred)\n",
    "\n",
    "#roc(\"Initial MNB with text counts from Count Vectorizer\", MNB, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "0GnFAENdyjv_",
    "outputId": "bab65860-b220-4601-c641-8cbcda9ad770"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1000}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#searching for optimum number of ensembles\n",
    "clf=RandomForestClassifier(criterion='gini',warm_start=True)\n",
    "parameters = {'n_estimators':[50,100,500,1000]}\n",
    "search =  GridSearchCV(clf,parameters)\n",
    "search.fit(X_train[0:0 + batchsize, :],Y_train[0:0 + batchsize]) #Only run through batchsize to determine the best params (whole dataset takes too much resource)\n",
    "bestparams =search.best_params_\n",
    "bestparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "H6u-9CJdyjv_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/Users/as76643/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score_RF = 82.59%\n",
      "[Best Params RF with text counts from Count Vectorizer] classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.89      0.76      0.82    192007\n",
      "     Neutral       0.77      0.95      0.85    261925\n",
      "    Positive       0.89      0.71      0.79    165012\n",
      "\n",
      "    accuracy                           0.83    618944\n",
      "   macro avg       0.85      0.81      0.82    618944\n",
      "weighted avg       0.84      0.83      0.82    618944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_best = RandomForestClassifier(n_estimators=bestparams['n_estimators'],criterion='gini',warm_start=True)\n",
    "\n",
    "for x, y in batch_xy(X_train, Y_train, batchsize):\n",
    "  clf_best.fit(x, y)\n",
    "  \n",
    "y_pred = np.array([])\n",
    "for x in batch_x(X_test, batchsize):\n",
    "  y_pred = np.append(y_pred, clf_best.predict(x))\n",
    "\n",
    "accuracy_score_clf = metrics.accuracy_score(y_pred, Y_test)\n",
    "print('accuracy_score_RF = '+str('{:4.2f}'.format(accuracy_score_clf*100))+'%')\n",
    "report(\"Best Params RF with text counts from Count Vectorizer\", Y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6gmcdRqyjv_"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h4jxhBHzyjv_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iJ5F2_ZZyjv_"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(stop_words=\"english\",norm=\"l2\")\n",
    "text_count_2 = tfidf.fit_transform(data['processed_text'])\n",
    "\n",
    "#splitting the data in test and training\n",
    "#x_train, x_test, y_train, y_test = train_test_split(text_count_2, data['Sentiment'],test_size=0.25,random_state=5)\n",
    "x_train, x_test, y_train, y_test = train_test_split(text_count_2, data['Vote'],test_size=0.25,random_state=5)\n",
    "\n",
    "#Models - reinitialize models since running fit on already fitted model may return something weird (I could be wrong on this, not sure how sklearn fit works initially)\n",
    "clf=RandomForestClassifier(n_estimators=1000,criterion='gini',warm_start=True)\n",
    "#for index in range(10):\n",
    "\n",
    "for x, y in batch_xy(x_train, y_train, batchsize):\n",
    "  clf.fit(x, y)\n",
    "  break\n",
    "    \n",
    "y_pred = np.array([])\n",
    "for x in batch_x(x_test, batchsize):\n",
    "  y_pred = np.append(y_pred, clf.predict(x))\n",
    "\n",
    "accuracy_score_clf = metrics.accuracy_score(y_pred, y_test)\n",
    "print('accuracy_score_RandomForest = '+str('{:4.2f}'.format(accuracy_score_clf*100))+'%')\n",
    "report(\"Initial RF with text counts from Count Vectorizer\", y_test, y_pred)\n",
    "#roc(\"Initial MNB with text counts from Count Vectorizer\", MNB, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "iGCUMfsJFfkt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "#searching for best params\n",
    "\n",
    "#searching for optimum number of ensembles\n",
    "clf=RandomForestClassifier(criterion='gini',warm_start=True)\n",
    "parameters = {'n_estimators':[50,100,500,1000]}\n",
    "search =  GridSearchCV(clf,parameters)\n",
    "search.fit(X_train[0:0 + batchsize, :],y_train[0:0 + batchsize]) #Only run through batchsize to determine the best params (whole dataset takes too much resource)\n",
    "bestparams =search.best_params_\n",
    "print(bestparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "x7H44UFVGTmF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score_RF = 84.37%\n",
      "[Best Params RF with text counts from Tfidf Vectorizer] classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.87      0.81      0.84    192007\n",
      "     Neutral       0.81      0.94      0.87    261925\n",
      "    Positive       0.89      0.74      0.81    165012\n",
      "\n",
      "    accuracy                           0.84    618944\n",
      "   macro avg       0.86      0.83      0.84    618944\n",
      "weighted avg       0.85      0.84      0.84    618944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_best = RandomForestClassifier(n_estimators=bestparams['n_estimators'],criterion='gini',warm_start=True)\n",
    "\n",
    "\n",
    "for x, y in batch_xy(x_train, y_train, batchsize):\n",
    "  clf_best.fit(x, y)\n",
    "  break\n",
    "  \n",
    "y_pred = np.array([])\n",
    "for x in batch_x(x_test, batchsize):\n",
    "  y_pred = np.append(y_pred, clf_best.predict(x))\n",
    "\n",
    "accuracy_score_clf = metrics.accuracy_score(y_pred, y_test)\n",
    "print('accuracy_score_RF = '+str('{:4.2f}'.format(accuracy_score_clf*100))+'%')\n",
    "report(\"Best Params RF with text counts from Tfidf Vectorizer\", y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JzIE_kyeyjv_"
   },
   "outputs": [],
   "source": [
    "\n",
    "text_counts.toarray()\n",
    "# Convert raw frequency counts into TF-IDF (Term Frequency -- Inverse Document Frequency) values\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "fooTfmer = TfidfTransformer()\n",
    "\n",
    "# Again, fit and transform\n",
    "docs_tfidf = fooTfmer.fit_transform(text_counts)\n",
    "\n",
    "#splitting the data in test and training\n",
    "#from sklearn.model_selection() import train_test_split()\n",
    "#x_train, x_test, y_train, y_test = train_test_split(docs_tfidf, data['Sentiment'],test_size=0.25,random_state=5)\n",
    "x_train_tf, x_test_tf, y_train_tf, y_test_tf = train_test_split(docs_tfidf, data['Vote'],test_size=0.25,random_state=5)\n",
    "\n",
    "#Models - reinitialize models since running fit on already fitted model may return something weird (I could be wrong on this, not sure how sklearn fit works initially)\n",
    "clf=RandomForestClassifier(n_estimators=100,criterion='gini',warm_start=True)\n",
    "#for index in range(10):\n",
    "\n",
    "for x, y in batch_xy(x_train_tf, y_train_tf, batchsize):\n",
    "  clf.fit(x, y)\n",
    "  \n",
    "y_pred = np.array([])\n",
    "for x in batch_x(x_test_tf, batchsize):\n",
    "  y_pred = np.append(y_pred, clf.predict(x))\n",
    "\n",
    "accuracy_score_clf = metrics.accuracy_score(y_pred, y_test_tf)\n",
    "print('accuracy_score_RandomForest = '+str('{:4.2f}'.format(accuracy_score_clf*100))+'%')\n",
    "report(\"Initial RF with text counts from Count Vectorizer\", y_test_tf, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbzGHbfUIFjC"
   },
   "outputs": [],
   "source": [
    "#searching for best params\n",
    "\n",
    "clf=RandomForestClassifier(criterion='gini',warm_start=True)\n",
    "parameters = {'n_estimators':[50,100,500,1000]}\n",
    "search =  GridSearchCV(clf,parameters)\n",
    "search.fit(x_train_tf[0:0 + batchsize, :],y_train_tf[0:0 + batchsize]) #Only run through batchsize to determine the best params (whole dataset takes too much resource)\n",
    "bestparams =search.best_params_\n",
    "print(bestparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vNyMch4WIOfR"
   },
   "outputs": [],
   "source": [
    "clf_best = RandomForestClassifier(n_estimators=bestparams['n_estimators'],criterion='gini',warm_start=True)\n",
    "\n",
    "for x, y in batch_xy(x_train_tf, y_train_tf, batchsize):\n",
    "  clf_best.fit(x, y)\n",
    "  \n",
    "y_pred = np.array([])\n",
    "for x in batch_x(x_test_tf, batchsize):\n",
    "  y_pred = np.append(y_pred, clf_best.predict(x))\n",
    "\n",
    "accuracy_score_clf = metrics.accuracy_score(y_pred, y_test_tf)\n",
    "print('accuracy_score_RF = '+str('{:4.2f}'.format(accuracy_score_clf*100))+'%')\n",
    "report(\"Best Params RF with text counts from Count Vectorizer\", y_test_tf, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "re3Iozwdyjv_"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AzAsAetJyjv_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Naive_Bayes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
